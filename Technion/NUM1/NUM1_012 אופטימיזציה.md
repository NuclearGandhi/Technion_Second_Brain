---
aliases:
  - אופטימיזציה
---
# אופטימיזציה לא מוגבלת
בפרק זה נעסוק במציאת מינימום של פונקציה ב-$n$ משתנים. כלומר, עבור פונקציה $\phi:\mathbb{R}^{n}\to \mathbb{R}$, ומשתנה $\bar{x}=({x}_{1},{x}_{2},\dots,x_{n})^{T}$, נרצה למצוא את:
$$\min_{\bar{x}\in \mathbb{R}^{n}}\phi(\bar{x})$$
לבעיה זו קוראים **בעיית מינימיזציה/אופטימיזציה**.

>[!example] דוגמה: 
 >להלן מקרה פשוט בו $n=2$, $\bar{x}=({x}_{1},{x}_{2})^{T}$, והפונקציה נתונה:
 >$$\phi(\bar{x})={x}_{1}^{2}+{s}_{2}^{4}+1$$
 >קל לראות שלפונקציה הזאת יש ערך מינימלי $1$ בנקודה $\bar{x}^{*}=(0,0)^{T}$:
 >![[Pasted image 20240409080747.png|book|400]]
 >>הפונקציה ${x}_{1}^{2}+{x}_{2}^{4}+1$ בעלת ערך מינימלי מוחלט בראשית הצירים, ואין לה מקסימום. אם נהפוך אותה, נקבל את הפונקציה $-({x}_{1}^{2}+{x}_{2}^{4}+1)$. לפונקציה זאת יהיה מקסימום מוחלט בראשית הצירים, ולא יהיה מינימום.
 
בבעיות אמיתיות ללא פתרון טריוויאלי, אנו לרוב לא יכולים למצוא את הנקודות מינימום רק מלהסתכל על הבעיה. למעשה, לרוב גם לא נדע *כמה* נקודות מינימום מקומיות יש, ואם הנקודה שהגענו אליה היא בכלל הנקודת מינימום *הגלובלית*.

כדי לפתור בעיות מינימיזציה, נוכל להמיר אותם לבעיית [[NUM1_006 מערכת משוואות לא לינארית|מערכת משוואות לא לינארית]], ומשם לפתור בעזרת שיטת ניוטון. כדי לבצע את המרה זאת, נדרש כמו [[NUM1_006 מערכת משוואות לא לינארית#טור טיילור לפונקציות וקטוריות|מקודם]] לפתח טור טיילור, רק הפעם מסדר $3$:

>[!theorem] משפט: 
יהי $\bar{x}=({x}_{1},{x}_{2},\dots,x_{n})^{T}$ ו-$\bar{f}({f}_{1},{f}_{2},\dots,f_{m})^{T}$, ונניח כי $\bar{f}(\bar{x})$ בעל נגזרות מסדר שלישי לפחות. אזי, לוקטור כיוון $\bar{p}=({p}_{1},{p}_{2},\dots,p_{n})^{T}$, הקירוב טיילור לכל פונקציה $f_{i}$ בכל רכיב $x_{j}$ הוא:
>$$\phi(\bar{x}+\bar{p})=\phi(\bar{x})+\bar{\nabla }\phi(\bar{x})^{T}\bar{p}+\dfrac{1}{2}\bar{p}^{T}\bar{\nabla}^{2}\phi(\bar{x})\bar{p}+\mathcal{O}(\| \bar{p}\|_{}^{3} )$$
>כאשר $\bar{\nabla }\phi(\bar{x})$ הוא ה[[CAL2_007 נגזרות מכוונות וגרדיאנט#גרדיאנט|גרדיאנט]] של $\phi$, ו-$\bar{\nabla}^{^{2}}\phi(\bar{x})$ הוא ה[[CAL2_010 נקודות אקסטרמום#מטריצת הס|הסיין]] של $\phi(\bar{x})$:
>$$\begin{aligned}
\bar{\nabla}\phi(\bar{x})=\begin{pmatrix}
\dfrac{ \partial \phi }{ \partial {x}_{1} }  \\
\dfrac{ \partial \phi }{ \partial {x}_{2} }  \\
\vdots  \\
\dfrac{ \partial \phi }{ \partial x_{n} } 
\end{pmatrix} &  & \bar{\nabla }^{2}\phi(\bar{x})=\begin{pmatrix}
\dfrac{ \partial ^{2}\phi }{ \partial {x}_{1}^{2} } & \dfrac{ \partial ^{2}\phi }{ \partial {x}_{1}\partial {x}_{2} } & \cdots  & \dfrac{ \partial ^{2}\phi }{ \partial {x}_{1}\partial x_{n} } \\
\dfrac{ \partial ^{2}\phi }{ \partial {x}_{2}\partial {x}_{1} }     & \dfrac{ \partial ^{2}\phi }{ \partial {x}_{2}^{2} }  & \cdots  & \dfrac{ \partial ^{2}\phi }{ \partial {x}_{2}\partial x_{n} } \\
 \vdots  & \vdots  & \ddots  & \vdots   \\
\dfrac{ \partial ^{2}\phi }{ \partial x_{n}\partial x_{1} } & \dfrac{ \partial ^{2}\phi }{ \partial x_{n}\partial x_{2} }  & \cdots  & \dfrac{ \partial ^{2}\phi }{ \partial x_{n}^{2} }  
\end{pmatrix}
\end{aligned}$$
השארית $\mathcal{O}(\| \bar{p}\|_{}^{3})$ תלויה בנגזרות של $\phi$ מסדר שלישי ומעלה.

## פיתוח שיטת ניוטון
נניח של-$\phi$ נגזרת רציפות מסדר שני ($\phi \in C^{2}$). לכן, נוכל לפתח לה את הטור טיילור כפי שראינו מקודם. [[CAL2_010 נקודות אקסטרמום#משפט הנגזרת השנייה הכללי|נזכור]] מחדו"א 2 שכדי למצוא את המינימום של פונקציה רב משתנית, עלינו למצוא קודם נקודות חשודות, ואז למצוא אם ההסיין בנקודות אילו *מוגדר חיובית*.

>[!notes] הערה: 
 >שיטת ניוטון כאן רק יודעת למצוא לנו את הנקודות החשודות, אבל היא לא יודעת להבטיח לנו שהנקודות שנמצא הן נקודות מינימום.

כדי למצוא נקודות חשודות, נרצה לפתור את מערכת המשוואות הבאה:
$$\bar{f}(\bar{x})\equiv   \bar{\nabla}\phi(\bar{x})= \bar{0}$$
כלומר, אנו מחפשים מתי הנגזרת הראשונה של $\phi$ מתאפסת. את מערכת משוואות זו נוכל לפתור בעזרת [[NUM1_006 מערכת משוואות לא לינארית|שיטת ניוטון למערכת משוואות]].

נסמן את ההסיין של $\phi$ ב-$H$:
$$H(\bar{x})\equiv \bar{\nabla}^{2}\phi(\bar{x}^{*})$$
נשים לב ש-$H$ הוא בעצם היעקוביאן של $\bar{f}$. כלומר ש- $H(\bar{x})=J(\bar{x})$. כעת נוכל לרשום את [[NUM1_006 מערכת משוואות לא לינארית#אלגוריתם שיטת ניוטון למערכת משוואות לא לינאריות|האלגוריתם של שיטת ניוטון]] במונחים של הבעיית אופטימזציה שלנו:


### #אלגוריתם: שיטת ניוטון לאופטימיזציה לא מוגבלת
בהינתן בעיית מינימיזציה של $\phi(\bar{x})$ מעל $\mathbb{R}^{n}$, יהי ${x}_{0}$ ניחוש התחלתי.
עבור $k=0,1,\dots$ עד שנגיע להתכנסות:
- נפתור $H(\bar{x}_{k})\bar{p}_{k}=-\bar{f}(\bar{x}_{k})$ כדי למצוא את $\bar{p}_{k}$.
- נציב $\bar{x}_{k+1}=\bar{x}_{k}+\bar{p}_{k}$.

>[!example] דוגמה: 
 >נביט בפונקציה:
>$$\begin{aligned}
\phi(\bar{x})= & \dfrac{1}{2}\bigg ([1.5-{x}_{1}(1-{x}_{2})]^{2}+[2.25-{x}_{1}(1-{x}_{2}^{2})^{2}] \\
 & \quad \quad +[2.625-{x}_{1}(1-{x}_{2}^{3})]^{2}\bigg)
\end{aligned}$$
>נמצא את הנקודות הקריטיות ע"י המערכת משוואות:
>$$\bar{\nabla}\phi(\bar{x})=\bar{f}(\bar{x})=\bar{0}$$
>כאשר:
>$$\begin{aligned}
 {f}_{1}({x}_{1},{x}_{2}) & =-[1.5-{x}_{1}(1-{x}_{2})](1-{x}_{2})-[2.25-{x}_{1}(1-{x}_{2}^{2})](1-{x}_{2})^{2} \\[1ex]
 & \quad \quad -[2.625-{x}_{1}(1-{x}_{2}^{3})](1-{x}_{2}^{3}) \\[2ex]
 {f}_{2}({x}_{1},{x}_{2}) & ={x}_{1}[1.5-{x}_{1}(1-{x}_{2})]+2{x}_{1}{x}_{2}[2.25-{x}_{1}(1-{x}_{2}^{2})] \\[1ex]
 & \quad \quad+3{x}_{1}{x}_{2}^{2}[2.625-{x}_{1}(1-{x}_{2}^{3})]
\end{aligned}$$
מבחינת הפתרון האנליטי, נקבל שיש לפונקציה מינימום ב- $\bar{x}^{*}=(3,0.5)$, בו ערך הפונקציה הוא $\phi(\bar{x})=0$. בנוסף, יש גם [[CAL2_010 נקודות אקסטרמום#מבחן הנגזרת השנייה|נקודת אוכף]] ב- $\hat{x}=(0,1)$, כך שגם בו הגרדיאנט מתאפס, ואז $\bar{f}(\hat{x})=\bar{0}$.
>
![[Pasted image 20240409094256.png|book]]
>>הפונקציה הנתונה בדוגמה. יש לה מינימום ב- $\bar{x}^{*}=(3,0.5)$ וגם נקודת אוכף ב-$\hat{x}=(0,1)$.
>
>אם נפעיל את שיטת ניוטון עם ניחוש התחלתי $\bar{x}_{0}=(8,0.2)$, נקבל את האיטרציות עם השגיאות הבאות:
>$$\begin{array}{c|c|c}
k & \| \bar{x}_{k}-\bar{x}^{*}\|_{} & \phi_{k}-\phi(\bar{x}^{*})  \\
\hline 0 & \pu{5.01} & \pu{8.17e1} \\
1 &  \pu {8.66e1 } &  \pu {2.42 }\\
2 &  \pu {6.49e-2 }  & \pu {2.41e-2 } \\
3  & \pu {1.39e-1 }  & \pu {3.45e-3 } \\
4  & \pu {2.10e-2 } &  \pu {1.38e-4 } \\
5 &  \pu {1.38e-3 }  & \pu {2.86e-7 } \\
6  & \pu {3.03e-6 } &  \pu {2.19e-12 } \\
7  & \pu {2.84e-11 }  & \pu {1.23e-22 }
\end{array}$$
קיבלנו התכנסות יחסית מהירה אל הפתרון $\bar{x}^{*}$.
אם היינו מתחילים מניחוש התחלתי $\bar{x}_{0}=(8,0.8)$ נקבל את האיטרציות עם השגיאות הבאות:
>$$\begin{array}{c|c|c}
k & \| \bar{x}_{k}-\bar{x}^{*}\|_{} & \phi_{k}-\phi(\bar{x}^{*})  \\
\hline 0 & \pu{5.01} & \pu{2.04} \\
1 &  \pu {3.96} &  \pu {2.55e-1 }\\
2 &  \pu {4.22 }  & \pu {2.33e-1 } \\
3  & \pu {1.66 }  & \pu {5.74e2 } \\
4  & \pu {6.14 } &  \pu {5.23e1 } \\
5 &  \pu {3.43}  & \pu {1.60e1 } \\
6  & \pu {3.04 } &  \pu {1.42e1 } \\
7  & \pu {3.04}  & \pu {1.42e1 }
\end{array}$$
>הפעם הפתרון שלנו יתכנס לנקודת אוכף, $\hat{x}$ ולא לנקודת מינימום!

## שיטות ירידת גרדיאנט וחזרה לאחור
ראינו מהדוגמה האחרונה שלפתור את בעיית המינימיזציה של פונקציה מסוימת יכולה להיות טיפה בעייתית.
נשים לב שלכל כיוון $\bar{p}$ בנקודה $\bar{x}$ בו הנגזרת לא מתאפסת ($\bar{f}(\bar{x})\neq 0$, אם $\| \bar{p}\|_{}$ קטן מספיק, אז כדי לקבל $\phi(\bar{x}+\bar{p})<\phi(\bar{x})$, נדרש שהנגזרת עצמה תהיה שלילית:
$$\bar{f}(\bar{x})^{T}\bar{p}=\bar{\nabla}\phi(\bar{x})^{T}\bar{p}<0$$
וקטור $\bar{p}$ שמקיים תנאי זה נקרא **כיוון ירידה** בנקודה $\bar{x}$. אם חושבים על הפונקציה $\phi$ במובן התלת ממדי (כמשטח), $\bar{p}$ כזה בנקודה מסוימת $\bar{x}$ מתאר את הכיוון בו כדור המונח בנקודה $\bar{x}$ יתגלגל על המשטח (ניזכר ב[[CAL2_007 נגזרות מכוונות וגרדיאנט#הקשר בין גרדיאנט לנגזרת מכוונת|קשר בין גרדיאנט לנגזרת מכוונת]] מחדו"א 2).

לשיטת ניוטון שראינו יש מספר יתרונות כמו התכנסות ריבועית. אבל, יש לה גם המון חסרונות:
1. נדרש הקיום של ההסיין.
2. נדרש *חישוב* של ההסיין.
3. נדרש לפתור מערכת משוואות לינארית בכל איטרציה.
4. לא ניתן לדעת אם השיטה תתכנס בכלל לנקודת מינימום, מקסימום או אפילו אוכף.

נביט בשיטה הבאה לטיפול בחסרונות אלו:

### ירידת גרדיאנט (gradient descent)
במקום לפתור את המערכת משוואות $H(\bar{x})\bar{p}_{k}=-\bar{f}(\bar{x}_{k})$ כדי למצוא את $\bar{p}_{k}$, נבחר במקום זאת את $\bar{p}_{k}$ להיות:
$$\boxed {
\bar{p}_{k}=-\nabla \phi(\bar{x}_{k})
 }$$
בחירת $\bar{p}$ זה מבטיחה שנתקדם בכיוון הירידה. בנוסף, נמנעו מלפתור מערכת משוואות לינארית!
מצד שני, אנו נאלצים לבחור גודל צעד $\alpha_{k}$. מעבר לכך, שיטה זו מתכנסת מאוד לאט.


### חיפוש קווי וחזרה לאחור
שיטות **חיפוש קווי (line search)** הן שיטות המתייחסות למציאת גודל צעד $\alpha_{k}$ מתאים עבור העדכון של האיטרציה שלנו:
$$\bar{x}_{k+1}=\bar{x}_{k}+\alpha_{k}\bar{p}_{k}$$
בשיטת ניוטון עבור מערכת משוואות לא לינאריות, מאחורי הקלעים כבר בחרנו $\alpha_{k}=1$. הבעיה, שאנו לא בהכרח נוכל לדעת האם עם בחירה זו השיטה שלנו תתכנס.
לפיכך, בהינתן $\bar{x}_{k}$ וכיוון ירידה $\bar{p}_{k}$, אנו נחפש לאורך ה*קו* $\bar{x}_{k}+\alpha \bar{p}_{k}$ את הערך $\alpha_{k}$ עבורו מתקיים:
$$\boxed {
\phi(\bar{x}_{k+1})\equiv \phi (\bar{x}_{k}+\alpha_{k}\bar{p}_{k})\leq \phi(\bar{x}_{k})+\sigma\alpha_{k} \bar{\nabla}\phi(\bar{x}_{k})^{T}\bar{p}_{k}
 }$$
כאשר $\sigma$ הוא קבוע שנותן לנו את תנאי העצירה, למשל $\sigma=\pu{e-4}$. בדרך כלל, נתחיל מערך מקסימלי $\alpha=\alpha_{\max_{}}$ כלשהו, וננמיך אותו אם יש צורך.
שיטה פשוטה הנקראת **חזרה לאחור (backtracking)** היא לבדוק את השיפור שלנו בין בחירת $\alpha$-ות שונות:
$$\boxed {
\dfrac{\alpha}{\alpha_{\max_{}}}=1,\, \dfrac{1}{2},\, \dfrac{1}{4},\dots ,\left( \dfrac{1}{2} \right)^{j},\dots
 } $$
נעצור כאשר קיבלנו את התנאי עצירה לעיל.



---
**תרגיל**:
חברת חלב רוצה לייצר חמאה. היא רוצה לדעת מהו המחיר האופטימלי שיאפשר לה להרוויח הכי הרבה. החברה חושבת שהיא יכולה לייצר $n$ יחידות למחיר הבא:
$$\text{Cost}=3n+\pu {10000 }$$

בנוסף, לאחר סקר שוק, הם מצאו את הנוסחה הבאה שמייצגת את הביקוש כתלות המחיר $x$:
$$\text{Demand}=\dfrac{\pu{500000}}{x^{2}}$$
לכן, כמות החמאה שהם יכולים למכור היא $n=\dfrac{\pu{500000}}{x^{2}}$, וההכנסה שלהם תהיה:
$$\text{Revenue}=\text{Demand}\times x=\dfrac{\pu{50000}}{x}$$
לבסוף, החברה יכולה לבנות את פונקציית הרווח:
$$\text{Profit}=\text{Revenue}-\text{Cost}=\dfrac{\pu{500000}}{x}-\dfrac{\pu{1500000}}{x^{2}}-\pu{10000}$$
בעזרת ירידת גרדיאנט, מצאו את המחיר האופטימלי. התחילו מ- ${x}_{0}=3$ ובצעו $20$ איטרציות עבור צעד קבוע:
- $\alpha_{k}=0.00001$
- $\alpha_{k}=0.0001$
- $\alpha_{k}=0.01$

איזה צעד מתכנס הכי מהר לפתרון?

**פתרון**:
נרצה למקסמם את הרווח, ולכן נשים מינוס על הפונקציה, כך שנהפוך את הבעיה למציאת מינימום של הפונקציה:
$$\phi(x)=\dfrac{\pu {1500000 }}{x^{2}}-\dfrac{\pu{500000}}{x}+\pu{10000}$$
נמצא כי הגרדיאנט של הפונקציה:
$${\nabla}\phi({x})=-\dfrac{\pu{3000000}}{x^{3}}+\dfrac{\pu{500000}}{x^{2}}$$
הכיוון שלנו הוא ${p}_{k}=-{\nabla}\phi({x})$. נציב בביטוי שלנו עבור ${x}_{k+1}$:
$$\begin{aligned}
{x}_{k+1} & ={x}_{k}+\alpha_{k}{p}_{k} \\
 & ={x}_{k}-\alpha_{k}{\nabla}\phi({x})
\end{aligned}$$
עבור $\alpha_{k}=0.00001$:
$$\begin{aligned}
 & {x}_{1}={x}_{0}-0.00001\nabla \phi({x}_{0})=3-0.00001\cdot(\pu{-5.556e4})=3.5556 \\[1ex]
 & {x}_{2}={x}_{1}-0.00001\nabla \phi({x}_{1})=3.5556-0.00001\cdot(\pu{-.2719e4})=3.8275
\end{aligned}$$

באותו אופן עבור ה-$\alpha_{k}$-ות האחרות, נקבל אחרי $20$ איטרציות:
![[Pasted image 20240409120400.png|book]]

עבור שני הצעדים הקטנים, השיטה מתכנסת למינימום של פונקציית המחיר, $x^{*}=6$ - כלומר המקסימום של הרווח.
עם $\alpha_{k}=0.0001$ השיטה קודם "קופצת" מעבר לפתרון, אבל היא עדיין מתכנסת יותר מהר מהשיטה עם $\alpha_{k}=0.00001$. לעומת זאת, אנו רואים שעבור $\alpha_{k}=0.01$ השיטה לא מתכנסת.
לסיכום, אפשר לומר שהשיטה מתכנסת הכי מהר עבור $\alpha_{k}=0.0001$.

---
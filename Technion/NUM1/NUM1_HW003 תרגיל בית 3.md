---
aliases:
---
# תרגיל בית 3

|  | סטודנט א' | סטודנט ב' |
| ---- | ---- | ---- |
| **שם** | עידו פנג בנטוב | ניר קרל |
| **ת"ז** | 322869140 | 322437203 |
| **דואר אלקטרוני** | ido.fang@campus.technion.ac.il | nir.karl@campus.technion.ac.il |


## תרגיל 1
$$
x^{(n+1)}=(I-\omega D^{-1}A)x^{(n)}+\alpha D^{-1}b
$$

### סעיף א'
נניח כי האיטרציות מתכנסות לפתרון $\bar{x}^{*}$, כלומר ש- $\bar{x}^{(k)}\xrightarrow[k\to \infty]{}\bar{x}^{*}$.
נציב בשיטה:
$$
\begin{gather}
x^{*}=(I-\omega D^{-1}A)x^{*}+\alpha D^{-1}b \\
(I-I+\omega D^{-1}A)x^{*}=\alpha D^{-1}b \\
\omega D^{-1}Ax^{*}=\alpha D^{-1}b \\
\omega Ax^{*}=\alpha b \\
Ax^{*}=\dfrac{\alpha}{\omega}b
\end{gather}
$$
היות ו-$x^{*}$ הוא פתרון של המערכת, הוא מקיים $Ax^{*}=b$, ולכן:
$$
\begin{gather}
\dfrac{\alpha}{\omega}=1 \\
\boxed {
\alpha=\omega
 }
\end{gather}
$$

### סעיף ב'
נציב $\omega=1$:
$$
\begin{gather}
x^{(n+1)}=(I-D^{-1}A)x^{(n)}+D^{-1}b \\
x^{(n+1)}=x^{(n)}+D^{-1}(b-Ax^{(n)})
\end{gather}
$$
זוהי הצורה המטריציונית של שיטת יעקובי.

### סעיף ג'
כתיב אינדקסי לצורה המטריציונית האחרונה שקיבלנו, רק הפעם לא נציב $\omega=1$:
$$
x_{i}^{(n)}=x_{i}^{(n-1)}+\dfrac{\omega}{a_{ii}}\left( b_{i}-\sum_{j=1}^{n} a_{ij}x_{i}^{(n-1)} \right)
$$

### סעיף ד'
נרשום את השיטה האיטרטיבית בצורה מטריציונית כך שנקבל משוואה מהצורה:
$$
x^{(n+1)}=Gx^{(n)}+c
$$
נשים לב שהיא כבר נתונה לנו בהתחלה בצורה זו ולכן:
$$
G=I-\omega D^{-1}A,\, \quad c=\omega D^{-1}b
$$
תנאי מספיק והכרחי להתכנסות הוא שהרדיוס הספקטרלי $\rho$ של $G$ יקיים:
$$
\rho(G)<1
$$
נמצא ע"ע של $G$:
$$
\begin{gather}
|I-\omega D^{-1}A-\lambda I|=0 \\[1ex]
|\omega D^{-1}A-I+\lambda I|=0 \\[1ex]
|\omega D^{-1}A-(1-\lambda)I|=0 \\[1ex]
\left|D^{-1}A-\dfrac{1-\lambda}{\omega}I\right|=0
\end{gather}
$$

נתון ש-$\lambda_{\max_{}}$ ו-$\lambda_{\min_{}}$ הם ע"ע של $D^{-1}A$, ולכן:
$$
\begin{gather}
|D^{-1}A-\lambda_{\max_{}} I|=0 \\[1ex]
|D^{-1}A-\lambda_{\min_{}}I|=0
\end{gather}
$$

נשווה מקדמים בין שתי המשוואות שקיבלנו:
$$
\dfrac{1-\lambda_{1,2}}{\omega}=\lambda _{\max_{},\min_{}}
$$
קיבלנו שהע"ע העצמיים, ${\lambda}_{1},\,{\lambda}_{2}$ של $G$ תלויים ב-$\lambda_{\max_{},\min_{}}$:
$$
\lambda_{1,2}=1-\omega\lambda_{\max_{},\min_{}}
$$

הרדיוס הספקטרלי של $G$ הוא המקסימלי ביניהם, ולכן:
$$
\begin{aligned}
\rho(G)&=\max_{}\{ {|\lambda}_{1}| ,{|\lambda}_{2}|  \} \\
&=\max_{}\{ |1-\omega \lambda_{\max_{}} |,\, |1-\omega\lambda_{\min_{}}|\} \\
&=\max_{}\{ \omega\lambda_{\max_{}}-1,\, 1-\omega\lambda_{\min_{}} \}
\end{aligned}
$$
כאשר בשוויון השלישי לקחנו בחשבון את הנתון ש-$\lambda_{\max_{},\min_{}}$ חיוביים וממשיים.
נדרוש ש-$\rho(G)<1$, אז נפרק למקרים:
$$
\begin{gather}
1-\omega\lambda_{\min_{}}<1 \\
-\omega\lambda_{\min_{}}<0 \\
\omega>0
\end{gather}
$$
או:
$$
\begin{gather}
\omega\lambda_{\max_{}}-1 < 1 \\
\omega\lambda_{\max_{}}<2 \\
\omega< \dfrac{2}{\lambda_{\max_{}}}
\end{gather}
$$
לסיכום:
$$
\boxed{0<\omega< \dfrac{2}{\lambda_{\max_{}}} }
$$

### סעיף ה'
קצב ההתכנסות נתון ע"י:
$$
\begin{aligned}
\text{rate} & =-\ln(\rho(G)) \\
 & =-\ln(\max_{}\{ \omega\lambda_{\max_{}}-1,\, 1-\omega\lambda_{\min_{}} \})
\end{aligned}
$$
כלומר, נצטרך למצוא מתי הביטוי ב-$\ln$ הוא *הכי קטן*.
כדי לקבל שהביטוי $\max_{}$ יהיה כמה שיותר קטן, נדרוש שהביטויים *בתוך* ה-$\max_{}$ יהיו שווים. אחרת, $\max_{}$ פשוט יבחר את הגדול מביניהם.
$$
\begin{gathered}
\omega\lambda_{\max_{}}-1=1-\omega\lambda_{\min_{}} \\[1ex]
\boxed {
\omega=\dfrac{2}{\lambda_{\min_{}}+\lambda_{\max_{}}}
 }
\end{gathered}
$$
לכן קצב ההתכנסות יהיה:
$$
\begin{aligned}
\text{rate} & =-\ln\left[ \dfrac{2}{\lambda_{\min_{}}+\lambda_{\max_{}}} \lambda_{\max_{}}-1\right] \\[1ex]
 & =\boxed {
-\ln\left[ \dfrac{\lambda_{\max_{}}-\lambda_{\min_{}}}{\lambda_{\max_{}}+\lambda_{\min_{}}} \right]
 }
\end{aligned}
$$

## תרגיל 2

### סעיף א'

$$
\begin{cases}
\sum_{A_{x}}^{}=F_{AC}\cdot \sin 45+H_{A}=0 \\
\sum_{A_{y}}^{}=F_{AB}+F_{AC}\cdot \cos 45=0\\
\sum_{B_{x}}^{}=F_{BC}+H_{B} =0\\
\sum_{B_{y}}^{}=V_{B}+F_{AB}=0\\
\sum_{C_{x}}^{}=F_{AC}\cdot \sin 45+F_{BC} =0\\
\sum_{C_{y}}^{}=F_{1}+F_{AC}\cdot \cos 45=0
\end{cases}
$$

### סעיף ב'

$$
\underbrace{\begin{pmatrix}
1 & 0 & 0 & 0 & 0 & \frac{1}{\sqrt{2}} \\
0 & 0 & 0 & 1 & 0 & \frac{1}{\sqrt{2}} \\
0 & 1 & 0 & 0 & 1 & 0 \\
0 & 0 & 1 & -1 & 0 & 0 \\
0 & 0 & 0 & 0 & 1 & \frac{1}{\sqrt{2}} \\
0 & 0 & 0 & 0 & 0 & \frac{1}{\sqrt{2}}
\end{pmatrix}}_{A}\underbrace{\begin{pmatrix}
H_{A} \\
H_{B} \\
V_{B} \\
F_{AB} \\
F_{BC} \\
F_{AC}
\end{pmatrix}}_{x}=\underbrace{\begin{pmatrix}
0 \\
0 \\
0 \\
0 \\
0 \\
-1
\end{pmatrix}}_{b}
$$

### סעיף ג'
```matlab
close all
clear;
clc;

A = [1, 0, 0, 0, 0, 1/sqrt(2);
0, 0, 0, 1, 0, 1/sqrt(2);
0, 1, 0, 0, 1, 0;
0, 0, 1, -1, 0, 0;
0, 0, 0, 0, 1, 1/sqrt(2);
0, 0, 0, 0, 0, 1/sqrt(2)];
x_ans = [1;-1;1;1;1;-sqrt(2)];
b = [0;0;0;0;0;-1];

A_T = A';

A_tilde = A_T*A;
b_tilde = A_T*b;

```
```matlab

k = 50;


x_jacobi = zeros(length(x_ans),1);
for i = 1:k
prev_x = x_jacobi(:);
x_jacobi = jacobi(A_tilde, b_tilde, x_jacobi);
r_j(i) = norm(A_tilde*x_jacobi-b_tilde, inf);
d_j(i) = norm(x_jacobi - prev_x, inf);
e_j(i) = norm(x_jacobi - x_ans, inf);
end

figure()
axes('XScale', 'linear', 'YScale', 'log')
hold on;
plot(1:k, r_j, "-");
plot(1:k, d_j, "-");
plot(1:k, e_j, "-");

x_gz = zeros(length(x_ans),1);
for i = 1:k
prev_x = x_gz(:);
x_gz = gz(A_tilde, b_tilde, x_gz);
r_gz(i) = norm(A_tilde*x_gz-b_tilde, inf);
d_gz(i) = norm(x_gz - prev_x, inf);
e_gz(i) = norm(x_gz - x_ans, inf);
end


plot(1:k, r_gz, "-");
plot(1:k, d_gz, "-");
plot(1:k, e_gz, "-");

legend("r Jacobi", "d Jacobi", "e Jacobi", "r GZ", "d GZ", "e GZ");
hold off;
```
```matlab
function x_k_1 = jacobi(A, b, x_k)
x_k_1 = x_k;
for i = 1 : length(x_k)
sum = 0;
for j = 1:length(x_k)
if j ~= i
sum = sum + A(i,j)*x_k(j);
end
end
x_k_1(i) = (1/A(i,i))*(b(i)-sum);
end
end

function x_k_1 = gz(A, b, x_k)
x_k_1 = x_k;
for i = 1 : length(x_k)
sum = 0;
for j = 1:i-1
sum = sum + A(i,j)*x_k_1(j);
end
for j = i:length(x_k)
sum = sum + A(i,j)*x_k(j);
end
x_k_1(i) = x_k(i) + (1/A(i,i))*(b(i)-sum);
end
end
```

![[Figure1.png|book|400]]

לפי הגרף ניתן לראות ש-$||r||_{\infty}$ ו-$||d||_{\infty}$ מתכנסים יחד עם $||e||_{\infty}$, ניתן לראות שבהתחלה השגיאה גדולה בהרבה מהנורמות האחרות, אך ככל שהאיטרציות מתקדמות הנורמות של $R,\;d$ נותנות קירוב יותר טוב של השגיאה.

כלומר בכמות איטרציות נמוכה הנורמות של $d$, $r$ אינן מתארות טוב את הנורמה של $e$ בצורה טובה. בכמות איטרציות גבוהה, הם מתארים את $e$ יחסית טוב.

  

### סעיף ד'

```matlab
G = eye(length(A_tilde)) - diag(diag(A_tilde))\A_tilde;
```

$$
\begin{aligned}
G&=I-Q^{-1}\tilde{A}  \\[2ex]
&=\begin{pmatrix}
0&	0&	0&	0&	0&	-0.7071\\
0&	0&	0&	0&	-1&	0\\
0&	0&	0&	1&	0&	0\\
0&	0&	0.5 & 0	&0	&-0.3536\\
0&	-0.5&	0&	0&	0&	-0.3536\\
-0.3536&	0&	0&	-0.3536&	-0.3536&	0\\
\end{pmatrix}
\end{aligned}
$$
נחשב נורמה של $G$ ב-`matlab`:

```matlab
>> norm(G, inf)
> ans =
>	1.0607
>	```
>	ולכן:
>	$$
>	||G||_{\infty} =1.0607
>	$$

כאשר $||G||_{\infty}<1$ השיטה מתכנסת, במקרה שלנו מכיוון שהנורמה גדולה מ-1 לא ניתן לדעת.

### סעיף ה'


נחשב את הע"ע של $G$ ב-`matlab`:
```matlab
>> eig(G)
> ans =
>	-0.9239
>	-0.3827
>	0.3827
>	0.9239
>	0.7071
>	-0.7071
>	```
>	ולכן, מאחר ו-$\rho(G)=\max_{}{\{ \lambda \}}$, אז:
>	$$
>	\rho(G)=0.9239
>	$$
>	ניתן לומר ששיטת יעקובי מתכנסת כי $\rho(G)<1$ הוא תנאי הכרחי ומספיק להתכנסות.


### סעיף ו'

```matlab
[a ,eig_G] = eig(G);
values = diag(eig_G);
max_val_abs = max(abs(values));

figure()
axes('XScale', 'linear', 'YScale', 'log')
hold on;
rho_G_vec = arrayfun(@(n) max_val_abs^n, 1:k);
plot(1:k, rho_G_vec, "-");
plot(1:k, e_j, "-");
legend("rho G", "norm e");
hold off;
```
```matlab
function x_k_1 = SOR(A, b, x_k, w)
x_k_1 = x_k;
for i = 1 : length(x_k)
sum = 0;
for j = 1:i-1
sum = sum + A(i,j)*x_k_1(j);
end
for j = i:length(x_k)
sum = sum + A(i,j)*x_k(j);
end
x_k_1(i) = x_k(i) + (w/A(i,i))*(b(i)-sum);
end
end
```

![[Figure2.png|book|400]]

מהגרף ניתן לראות ש- $\rho(G)^{n}$ הוא קירוב מאוד טוב של השגיאה שלנו.

  

### סעיף ז'
```matlab
figure();
axes('XScale', 'linear', 'YScale', 'log')
hold on;
for w = 0.75:0.25:1.75
x_SOR = zeros(length(x_ans),1);
e_SOR = zeros(k, 1);
for i = 1:k
x_SOR = SOR(A_tilde, b_tilde, x_SOR, w);
e_SOR(i) = norm(x_SOR - x_ans, inf);
end
semilogy(1:k, e_SOR, "-");
end
legend('w = 0.75', 'w = 1.00', 'w = 1.25', 'w = 1.50', 'w = 1.75')
hold off;
```


![[Figure3.png|book|400]]

מהגרף ניתן לראות שהשיטה מתכנסת הכי מהר עבור $\omega=1.5$.